{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphogenesis with Attention/Transformer Cellular Automata\n",
    "\n",
    "Let's use the code from `Render_MHA.ipynb` to train self-assembly into a particle system with dynamics defined by a multi-head attention block. \n",
    "\n",
    "We will compute the $\\ell_2$ distance between the target image and the particle system projection (Gaussian bitmap) and optimize the weights accordingly. \n",
    "\n",
    "I honestly don't know if the single MHA will be able to do it -- or if we will need multiple layers. I have a hunch that we can do this with an MHA and a non-linearity given enough latent states. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aman/Transformer_Phase_Space/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## Import box\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import glob \n",
    "import cv2\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device: \", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0: Dynamical MHA Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGB_render_particles_to_bitmap(X, x_res, y_res, sigma=1.0, scale_sigma=False):\n",
    "    \"\"\"\n",
    "    Renders colored particles as Gaussian distributions on an RGB bitmap.\n",
    "\n",
    "    Args:\n",
    "        X (torch.Tensor): A tensor of shape [N, d] where d >= 5, with the first two dimensions\n",
    "                          representing particle positions and the next three dimensions\n",
    "                          representing RGB colors of each particle.\n",
    "        x_res (int): The resolution of the bitmap along the x-axis.\n",
    "        y_res (int): The resolution of the bitmap along the y-axis.\n",
    "        sigma (float): The standard deviation of the Gaussians in pixels.\n",
    "        scale_sigma (bool): If True, scales sigma by the same factor as positions.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: An RGB bitmap of shape [x_res, y_res, 3] with rendered Gaussian\n",
    "                      distributions of particles, each colored according to its RGB value.\n",
    "    \"\"\"\n",
    "    # Initialize an empty RGB bitmap of shape [y_res, x_res, 3]\n",
    "    rgb_bitmap = torch.zeros((y_res, x_res, 3))\n",
    "\n",
    "    # Scale particle positions to fit within [-1, 1]\n",
    "    min_pos = torch.min(X[:, 0:2], dim=0)[0]\n",
    "    max_pos = torch.max(X[:, 0:2], dim=0)[0]\n",
    "    scale_factor = torch.max(max_pos - min_pos) / 2\n",
    "    scaled_X = (X[:, 0:2] - (min_pos + scale_factor)) / scale_factor\n",
    "\n",
    "    # Optionally scale sigma\n",
    "    if scale_sigma:\n",
    "        sigma *= scale_factor\n",
    "\n",
    "    # Generate a meshgrid for the bitmap coordinates\n",
    "    x = torch.linspace(-1, 1, steps=x_res)\n",
    "    y = torch.linspace(-1, 1, steps=y_res)\n",
    "    xx, yy = torch.meshgrid(x, y, indexing=\"ij\")\n",
    "\n",
    "    # For each particle, add its colored Gaussian distribution to the RGB bitmap\n",
    "    for i in range(X.shape[0]):\n",
    "        # Calculate Gaussian distribution\n",
    "        gx = torch.exp(-((xx - scaled_X[i, 0]) ** 2) / (2 * sigma ** 2))\n",
    "        gy = torch.exp(-((yy - scaled_X[i, 1]) ** 2) / (2 * sigma ** 2))\n",
    "        gaussian = gx * gy\n",
    "\n",
    "        # Apply color to Gaussian\n",
    "        for channel in range(3):\n",
    "            rgb_bitmap[:, :, channel] += gaussian * X[i, channel + 2]\n",
    "\n",
    "    # Normalize the RGB bitmap so the maximum Gaussian value is 1 for each channel\n",
    "    max_val = torch.max(rgb_bitmap.view(-1, 3), dim=0)[0]\n",
    "    rgb_bitmap /= max_val.clamp(min=1)  # Avoid division by zero\n",
    "\n",
    "    return rgb_bitmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_state_matrix(X_, \n",
    "                           title='State Visualization: XY-RGB State Interpretation', \n",
    "                           savename='../figs/test.png', \n",
    "                           scale_sigma=False,\n",
    "                           show=False):\n",
    "    # make the directories leading to savename if they don't exist \n",
    "    os.makedirs(os.path.dirname(savename), exist_ok=True)\n",
    "    \n",
    "    X = X_.detach().cpu()\n",
    "    bitmap = RGB_render_particles_to_bitmap(X, x_res, y_res, sigma=0.03, scale_sigma=scale_sigma)\n",
    "    plt.imshow(bitmap.numpy())\n",
    "    plt.title(title)\n",
    "    plt.savefig(savename)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sim(state_matrix, \n",
    "            num_iters = 50, \n",
    "            dt = 0.02 / 100, \n",
    "            noise_factor = 0.005,\n",
    "            fig_folder=None,\n",
    "            frame_period = 2000):\n",
    "    for i in tqdm(range(num_iters)): \n",
    "        dx, _ = multihead_attn(state_matrix, state_matrix, state_matrix)\n",
    "        dxy = dx[:,:,0:2]\n",
    "\n",
    "        # noise up the dxy \n",
    "        noise = torch.randn_like(dxy).to(DEVICE)*noise_factor  # 0 mean, variance 1\n",
    "        dxy += noise\n",
    "\n",
    "        # let's try normalizing dxy -- right now the variance is super tight.\n",
    "        dxy_std, dxy_mean = torch.std_mean(dxy)\n",
    "        dxy = dxy - dxy_mean\n",
    "        dxy = dxy/dxy_std\n",
    "\n",
    "        dxyrgb = torch.zeros(dx.shape).to(DEVICE) \n",
    "        dxyrgb[:,:,0:2] = dxy\n",
    "\n",
    "        state_matrix += dxyrgb*dt\n",
    "        \n",
    "        # savename = f'../figs/{fig_folder}/frame_{str(i).zfill(3)}.png'\n",
    "        if fig_folder is not None and i % frame_period == 0: \n",
    "            with torch.no_grad():\n",
    "                visualize_state_matrix(state_matrix[:,0,:], \n",
    "                                    scale_sigma=True,\n",
    "                                    savename=f'../figs/{fig_folder}/frame_{str(i//frame_period).zfill(3)}.png')\n",
    "    return state_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State matrix shape (N, batch, particle_state_dim):  torch.Size([200, 1, 40])\n"
     ]
    }
   ],
   "source": [
    "## Setting up the MHA \n",
    "embed_dim = 40      # Key and query dimension expected in the input.\n",
    "key_dim = 40        # Expected dimension of the keys + queries\n",
    "val_dim = 40        # Expected dimension of the \n",
    "num_heads = 4       # Number of heads in the MHA.\n",
    "multihead_attn = nn.MultiheadAttention(embed_dim, num_heads, kdim=key_dim, vdim=val_dim, bias=True).to(DEVICE) # value/outpu\n",
    "\n",
    "## Setting up the state matrix \n",
    "N = 200             # Number of particles/sequence length\n",
    "num_batch = 1\n",
    "\n",
    "state_matrix = torch.rand(N, num_batch, val_dim).to(DEVICE) # uniform [0, 1]\n",
    "print(\"State matrix shape (N, batch, particle_state_dim): \", state_matrix.shape)\n",
    "\n",
    "## Define a for loop that iterates thru some number of state updates\n",
    "num_iters = 10000\n",
    "dt = 0.02 / 100\n",
    "noise_factor = 0.005\n",
    "fig_folder='anim04'\n",
    "\n",
    "x_res = 500\n",
    "y_res = 500\n",
    "\n",
    "frame_period = 200\n",
    "# frame_period = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Running the Simulation/Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset output directory contents\n",
    "png_path = f'../figs/{fig_folder}/*.png'\n",
    "\n",
    "os.system(f'rm {png_path}')\n",
    "os.makedirs(f'../figs/{fig_folder}', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state_matrix = run_sim(state_matrix,\n",
    "                        num_iters=num_iters,\n",
    "                        dt=dt,\n",
    "                        noise_factor=noise_factor,\n",
    "                        fig_folder=fig_folder,\n",
    "                        frame_period=frame_period)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
